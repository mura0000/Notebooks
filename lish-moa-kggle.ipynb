{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:01.320356Z",
     "iopub.status.busy": "2020-11-28T12:01:01.319490Z",
     "iopub.status.idle": "2020-11-28T12:01:02.613286Z",
     "shell.execute_reply": "2020-11-28T12:01:02.612329Z"
    },
    "papermill": {
     "duration": 1.322037,
     "end_time": "2020-11-28T12:01:02.613436",
     "exception": false,
     "start_time": "2020-11-28T12:01:01.291399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:02.647847Z",
     "iopub.status.busy": "2020-11-28T12:01:02.646887Z",
     "iopub.status.idle": "2020-11-28T12:01:02.650208Z",
     "shell.execute_reply": "2020-11-28T12:01:02.649517Z"
    },
    "papermill": {
     "duration": 0.021865,
     "end_time": "2020-11-28T12:01:02.650340",
     "exception": false,
     "start_time": "2020-11-28T12:01:02.628475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:02.686502Z",
     "iopub.status.busy": "2020-11-28T12:01:02.685461Z",
     "iopub.status.idle": "2020-11-28T12:01:09.244162Z",
     "shell.execute_reply": "2020-11-28T12:01:09.243334Z"
    },
    "papermill": {
     "duration": 6.580136,
     "end_time": "2020-11-28T12:01:09.244289",
     "exception": false,
     "start_time": "2020-11-28T12:01:02.664153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/lish-moa/\"\n",
    "train_features = pd.read_csv(data_path + \"train_features.csv\")\n",
    "train_targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n",
    "test_features = pd.read_csv(data_path + \"test_features.csv\")\n",
    "sample_submission = pd.read_csv(data_path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:09.278269Z",
     "iopub.status.busy": "2020-11-28T12:01:09.277210Z",
     "iopub.status.idle": "2020-11-28T12:01:09.280891Z",
     "shell.execute_reply": "2020-11-28T12:01:09.280141Z"
    },
    "papermill": {
     "duration": 0.022657,
     "end_time": "2020-11-28T12:01:09.281029",
     "exception": false,
     "start_time": "2020-11-28T12:01:09.258372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = train_features.columns\n",
    "target_names = sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:09.316597Z",
     "iopub.status.busy": "2020-11-28T12:01:09.315760Z",
     "iopub.status.idle": "2020-11-28T12:01:09.374999Z",
     "shell.execute_reply": "2020-11-28T12:01:09.375573Z"
    },
    "papermill": {
     "duration": 0.079746,
     "end_time": "2020-11-28T12:01:09.375729",
     "exception": false,
     "start_time": "2020-11-28T12:01:09.295983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_0004d9e33</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001897cda</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_002429b5b</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00276f245</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0027f1083</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "sig_id                                                              \n",
       "id_0004d9e33                 1.000000e-15            1.000000e-15   \n",
       "id_001897cda                 1.000000e-15            1.000000e-15   \n",
       "id_002429b5b                 1.000000e-15            1.000000e-15   \n",
       "id_00276f245                 1.000000e-15            1.000000e-15   \n",
       "id_0027f1083                 1.000000e-15            1.000000e-15   \n",
       "\n",
       "              acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "sig_id                                                         \n",
       "id_0004d9e33    1.000000e-15                    1.000000e-15   \n",
       "id_001897cda    1.000000e-15                    1.000000e-15   \n",
       "id_002429b5b    1.000000e-15                    1.000000e-15   \n",
       "id_00276f245    1.000000e-15                    1.000000e-15   \n",
       "id_0027f1083    1.000000e-15                    1.000000e-15   \n",
       "\n",
       "              acetylcholine_receptor_antagonist  \\\n",
       "sig_id                                            \n",
       "id_0004d9e33                       1.000000e-15   \n",
       "id_001897cda                       1.000000e-15   \n",
       "id_002429b5b                       1.000000e-15   \n",
       "id_00276f245                       1.000000e-15   \n",
       "id_0027f1083                       1.000000e-15   \n",
       "\n",
       "              acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "sig_id                                                                     \n",
       "id_0004d9e33                    1.000000e-15                1.000000e-15   \n",
       "id_001897cda                    1.000000e-15                1.000000e-15   \n",
       "id_002429b5b                    1.000000e-15                1.000000e-15   \n",
       "id_00276f245                    1.000000e-15                1.000000e-15   \n",
       "id_0027f1083                    1.000000e-15                1.000000e-15   \n",
       "\n",
       "              adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "sig_id                                                                    \n",
       "id_0004d9e33                   1.000000e-15                1.000000e-15   \n",
       "id_001897cda                   1.000000e-15                1.000000e-15   \n",
       "id_002429b5b                   1.000000e-15                1.000000e-15   \n",
       "id_00276f245                   1.000000e-15                1.000000e-15   \n",
       "id_0027f1083                   1.000000e-15                1.000000e-15   \n",
       "\n",
       "              adrenergic_receptor_agonist  ...  \\\n",
       "sig_id                                     ...   \n",
       "id_0004d9e33                 1.000000e-15  ...   \n",
       "id_001897cda                 1.000000e-15  ...   \n",
       "id_002429b5b                 1.000000e-15  ...   \n",
       "id_00276f245                 1.000000e-15  ...   \n",
       "id_0027f1083                 1.000000e-15  ...   \n",
       "\n",
       "              tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "sig_id                                                              \n",
       "id_0004d9e33                           1.000000e-15  1.000000e-15   \n",
       "id_001897cda                           1.000000e-15  1.000000e-15   \n",
       "id_002429b5b                           1.000000e-15  1.000000e-15   \n",
       "id_00276f245                           1.000000e-15  1.000000e-15   \n",
       "id_0027f1083                           1.000000e-15  1.000000e-15   \n",
       "\n",
       "              trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "sig_id                                                                        \n",
       "id_0004d9e33     1.000000e-15       1.000000e-15               1.000000e-15   \n",
       "id_001897cda     1.000000e-15       1.000000e-15               1.000000e-15   \n",
       "id_002429b5b     1.000000e-15       1.000000e-15               1.000000e-15   \n",
       "id_00276f245     1.000000e-15       1.000000e-15               1.000000e-15   \n",
       "id_0027f1083     1.000000e-15       1.000000e-15               1.000000e-15   \n",
       "\n",
       "              ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  \\\n",
       "sig_id                                                                 \n",
       "id_0004d9e33                           1.000000e-15     1.000000e-15   \n",
       "id_001897cda                           1.000000e-15     1.000000e-15   \n",
       "id_002429b5b                           1.000000e-15     1.000000e-15   \n",
       "id_00276f245                           1.000000e-15     1.000000e-15   \n",
       "id_0027f1083                           1.000000e-15     1.000000e-15   \n",
       "\n",
       "                 vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "sig_id                                                                 \n",
       "id_0004d9e33  1.000000e-15                1.000000e-15   1.000000e-15  \n",
       "id_001897cda  1.000000e-15                1.000000e-15   1.000000e-15  \n",
       "id_002429b5b  1.000000e-15                1.000000e-15   1.000000e-15  \n",
       "id_00276f245  1.000000e-15                1.000000e-15   1.000000e-15  \n",
       "id_0027f1083  1.000000e-15                1.000000e-15   1.000000e-15  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.set_index('sig_id', inplace=True)\n",
    "submission.loc[:,:] = 1e-15\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:09.417441Z",
     "iopub.status.busy": "2020-11-28T12:01:09.416476Z",
     "iopub.status.idle": "2020-11-28T12:01:09.419061Z",
     "shell.execute_reply": "2020-11-28T12:01:09.419652Z"
    },
    "papermill": {
     "duration": 0.028711,
     "end_time": "2020-11-28T12:01:09.419832",
     "exception": false,
     "start_time": "2020-11-28T12:01:09.391121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(features, targets=None):\n",
    "    #indices to retain for training\n",
    "    ret_indices = features['cp_type'] != 'ctl_vehicle'\n",
    "    \n",
    "    #process features\n",
    "    X = features.copy()\n",
    "    X = X.loc[ret_indices, :]\n",
    "    id_ = X['sig_id']\n",
    "    X.drop(columns=['sig_id', 'cp_type'], inplace=True)\n",
    "    X = pd.get_dummies(X, columns=['cp_time', 'cp_dose'])\n",
    "    \n",
    "    if targets is not None:\n",
    "        Y = targets.copy().loc[ret_indices, :]\n",
    "        Y.drop(columns=['sig_id'], inplace=True)\n",
    "        \n",
    "        return id_, X, Y\n",
    "    else:\n",
    "        \n",
    "        return id_, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:09.460972Z",
     "iopub.status.busy": "2020-11-28T12:01:09.460226Z",
     "iopub.status.idle": "2020-11-28T12:01:09.981573Z",
     "shell.execute_reply": "2020-11-28T12:01:09.980723Z"
    },
    "papermill": {
     "duration": 0.546402,
     "end_time": "2020-11-28T12:01:09.981701",
     "exception": false,
     "start_time": "2020-11-28T12:01:09.435299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_train, X_train, Y_train = preprocessing(train_features, train_targets)\n",
    "id_test, X_test = preprocessing(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:10.031911Z",
     "iopub.status.busy": "2020-11-28T12:01:10.028885Z",
     "iopub.status.idle": "2020-11-28T12:01:10.048003Z",
     "shell.execute_reply": "2020-11-28T12:01:10.048660Z"
    },
    "papermill": {
     "duration": 0.051755,
     "end_time": "2020-11-28T12:01:10.048852",
     "exception": false,
     "start_time": "2020-11-28T12:01:09.997097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>-0.0921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>1.2300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>-1.0600</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      g-0     g-1     g-2     g-3     g-4     g-5     g-6     g-7     g-8  \\\n",
       "0  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220 -0.0326  0.5548   \n",
       "1  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341  0.3372 -0.4047   \n",
       "2  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715  0.2155  0.0065   \n",
       "3 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590  0.1792 -0.1321   \n",
       "4 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800 -0.1498 -0.8789   \n",
       "\n",
       "      g-9  ...    c-95    c-96    c-97    c-98    c-99  cp_time_24  \\\n",
       "0 -0.0921  ...  0.6584 -0.3981  0.2139  0.3801  0.4176           1   \n",
       "1  0.8507  ...  0.4899  0.1522  0.1241  0.6077  0.7371           0   \n",
       "2  1.2300  ... -0.3174 -0.6417 -0.2187 -1.4080  0.6931           0   \n",
       "3 -1.0600  ... -1.2880 -1.6210 -0.8784 -0.3876 -0.8154           0   \n",
       "4  0.8630  ... -0.3031  0.1094  0.2885 -0.3786  0.7125           0   \n",
       "\n",
       "   cp_time_48  cp_time_72  cp_dose_D1  cp_dose_D2  \n",
       "0           0           0           1           0  \n",
       "1           0           1           1           0  \n",
       "2           1           0           1           0  \n",
       "3           1           0           1           0  \n",
       "4           0           1           0           1  \n",
       "\n",
       "[5 rows x 877 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:10.102403Z",
     "iopub.status.busy": "2020-11-28T12:01:10.099926Z",
     "iopub.status.idle": "2020-11-28T12:01:10.122792Z",
     "shell.execute_reply": "2020-11-28T12:01:10.122079Z"
    },
    "papermill": {
     "duration": 0.05564,
     "end_time": "2020-11-28T12:01:10.122962",
     "exception": false,
     "start_time": "2020-11-28T12:01:10.067322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>-0.2140</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>-0.3260</td>\n",
       "      <td>1.9390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>-1.8820</td>\n",
       "      <td>0.4022</td>\n",
       "      <td>-0.3528</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>-0.1799</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>-1.1120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>-0.6898</td>\n",
       "      <td>-1.6270</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>-0.3832</td>\n",
       "      <td>-0.4653</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6570</td>\n",
       "      <td>-0.2593</td>\n",
       "      <td>-0.2174</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-1.4650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      g-0     g-1     g-2     g-3     g-4     g-5     g-6     g-7     g-8  \\\n",
       "0 -0.5458  0.1306 -0.5135  0.4408  1.5500 -0.1644 -0.2140  0.2221 -0.3260   \n",
       "1 -0.1829  0.2320  1.2080 -0.4522 -0.3652 -0.3319 -1.8820  0.4022 -0.3528   \n",
       "3  0.4828  0.1955  0.3825  0.4244 -0.5855 -1.2020  0.5998 -0.1799  0.9365   \n",
       "4 -0.3979 -1.2680  1.9130  0.2057 -0.5864 -0.0166  0.5128  0.6365  0.2611   \n",
       "6  0.3658  0.5536 -0.6898 -1.6270  0.5239 -0.3832 -0.4653  1.0070  0.3726   \n",
       "\n",
       "      g-9  ...    c-95    c-96    c-97    c-98    c-99  cp_time_24  \\\n",
       "0  1.9390  ... -0.1193  0.0210 -0.0502  0.1510 -0.7750           1   \n",
       "1  0.1271  ... -0.5382  0.0359 -0.4764 -1.3810 -0.7300           0   \n",
       "3  0.2942  ... -0.9005  0.8131 -0.1305  0.5645 -0.5809           1   \n",
       "4 -1.1120  ...  1.0900 -0.2962 -0.5313  0.9931  1.8380           0   \n",
       "6  0.0811  ... -0.6570 -0.2593 -0.2174  0.0044 -1.4650           0   \n",
       "\n",
       "   cp_time_48  cp_time_72  cp_dose_D1  cp_dose_D2  \n",
       "0           0           0           1           0  \n",
       "1           0           1           1           0  \n",
       "3           0           0           0           1  \n",
       "4           1           0           1           0  \n",
       "6           1           0           0           1  \n",
       "\n",
       "[5 rows x 877 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:10.209502Z",
     "iopub.status.busy": "2020-11-28T12:01:10.172981Z",
     "iopub.status.idle": "2020-11-28T12:01:17.516072Z",
     "shell.execute_reply": "2020-11-28T12:01:17.515252Z"
    },
    "papermill": {
     "duration": 7.375478,
     "end_time": "2020-11-28T12:01:17.516217",
     "exception": false,
     "start_time": "2020-11-28T12:01:10.140739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "#from tensorflow.keras.layers import LeakyReLu\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "\n",
    "prod_cols = lambda df, cols: pd.DataFrame(df[cols].prod(axis=1))\n",
    "var_cols = lambda df, cols: pd.DataFrame(df[cols].var(axis=1))\n",
    "mean_cols = lambda df, cols: pd.DataFrame(df[cols].mean(axis=1))\n",
    "quantiles_cols = lambda df, cols, q: pd.DataFrame(df[cols].quantile(q, axis=1)).transpose()\n",
    "skew_cols = lambda df, cols: pd.DataFrame(df[cols].skew(axis=1))\n",
    "kurt_cols = lambda df, cols: pd.DataFrame(df[cols].kurtosis(axis=1))\n",
    "\n",
    "\n",
    "def generate_X_pca(X_tr, X_val, X_test, num_comp_g=None, num_comp_c=None):\n",
    "    N_tr = X_tr.shape[0]\n",
    "    N_val = X_val.shape[0]\n",
    "    N_test = X_test.shape[0]\n",
    "    \n",
    "    g_cols = list(X_tr.columns[list(map(lambda x: x[0:2]=='g-', X_tr.columns))])\n",
    "    c_cols = list(X_tr.columns[list(map(lambda x: x[0:2]=='c-', X_tr.columns))])\n",
    "    other_cols = list(set(X_tr.columns) - set(g_cols  + c_cols))\n",
    "    \n",
    "    #Create columns for values of PC transformation\n",
    "    pca_g = PCA()\n",
    "    X_tr_pca_g = pca_g.fit_transform(X_tr[g_cols])[:,0:num_comp_g]\n",
    "    X_val_pca_g = pca_g.transform(X_val[g_cols])[:,0:num_comp_g]\n",
    "    X_test_pca_g = pca_g.transform(X_test[g_cols])[:,0:num_comp_g]\n",
    "    \n",
    "    pca_c = PCA()\n",
    "    X_tr_pca_c = pca_c.fit_transform(X_tr[c_cols])[:,0:num_comp_c]\n",
    "    X_val_pca_c = pca_c.transform(X_val[c_cols])[:,0:num_comp_c]\n",
    "    X_test_pca_c = pca_c.transform(X_test[c_cols])[:,0:num_comp_c]\n",
    "    \n",
    "    #Columns for one-hot encoded variables\n",
    "    X_tr_others = X_tr[other_cols]\n",
    "    X_val_others = X_val[other_cols]\n",
    "    X_test_others = X_test[other_cols]\n",
    "    \n",
    "    \n",
    "    #Columns for variance of g and of c variables\n",
    "    X_tr_g_var = var_cols(X_tr, g_cols)\n",
    "    X_val_g_var = var_cols(X_val, g_cols)\n",
    "    X_test_g_var = var_cols(X_test, g_cols)\n",
    "    \n",
    "    X_tr_c_var = var_cols(X_tr, c_cols)\n",
    "    X_val_c_var = var_cols(X_val, c_cols)\n",
    "    X_test_c_var = var_cols(X_test, c_cols)\n",
    "    \n",
    "    #Columns for mean g and of c variables\n",
    "    X_tr_g_mean = mean_cols(X_tr, g_cols)\n",
    "    X_val_g_mean = mean_cols(X_val, g_cols)\n",
    "    X_test_g_mean = mean_cols(X_test, g_cols)\n",
    "    \n",
    "    X_tr_c_mean = mean_cols(X_tr, c_cols)\n",
    "    X_val_c_mean = mean_cols(X_val, c_cols)\n",
    "    X_test_c_mean = mean_cols(X_test, c_cols)\n",
    "    \n",
    "    #Columns for the difference between the mean of g variables and that of c variables\n",
    "    X_tr_mean_diff = X_tr_g_mean - X_tr_c_mean\n",
    "    X_val_mean_diff = X_val_g_mean - X_val_c_mean\n",
    "    X_test_mean_diff = X_test_g_mean - X_test_c_mean\n",
    "    \n",
    "    #Columns for quantiles of g and of c variables\n",
    "    q = np.linspace(0, 1, num=22)\n",
    "    \n",
    "    X_tr_g_quantiles = quantiles_cols(X_tr, g_cols, q)\n",
    "    X_val_g_quantiles = quantiles_cols(X_val, g_cols, q)\n",
    "    X_test_g_quantiles = quantiles_cols(X_test, g_cols, q)\n",
    "    \n",
    "    X_tr_c_quantiles = quantiles_cols(X_tr, c_cols, q)\n",
    "    X_val_c_quantiles = quantiles_cols(X_val, c_cols, q)\n",
    "    X_test_c_quantiles = quantiles_cols(X_test, c_cols, q)\n",
    "    \n",
    "    #Columns for skewness of g and of c variables\n",
    "    X_tr_g_skew = skew_cols(X_tr, g_cols)\n",
    "    X_val_g_skew = skew_cols(X_val, g_cols)\n",
    "    X_test_g_skew = skew_cols(X_test, g_cols)\n",
    "    \n",
    "    X_tr_c_skew = skew_cols(X_tr, c_cols)\n",
    "    X_val_c_skew = skew_cols(X_val, c_cols)\n",
    "    X_test_c_skew = skew_cols(X_test, c_cols)\n",
    "    \n",
    "    #Columns for kurtosis of g and of c variables\n",
    "    X_tr_g_kurt = kurt_cols(X_tr, g_cols)\n",
    "    X_val_g_kurt = kurt_cols(X_val, g_cols)\n",
    "    X_test_g_kurt = kurt_cols(X_test, g_cols)\n",
    "    \n",
    "    X_tr_c_kurt = kurt_cols(X_tr, c_cols)\n",
    "    X_val_c_kurt = kurt_cols(X_val, c_cols)\n",
    "    X_test_c_kurt = kurt_cols(X_test, c_cols)\n",
    "    \n",
    "    \n",
    "    #Columns for mean * cp time\n",
    "    #24\n",
    "    X_tr_g_mean_24 = np.exp(X_tr_g_mean) * np.array(X_tr['cp_time_24']).reshape((N_tr, 1))\n",
    "    X_val_g_mean_24 = np.exp(X_val_g_mean) * np.array(X_val['cp_time_24']).reshape((N_val, 1))\n",
    "    X_test_g_mean_24 = np.exp(X_test_g_mean) * np.array(X_test['cp_time_24']).reshape((N_test, 1))\n",
    "    \n",
    "    X_tr_c_mean_24 = np.exp(X_tr_c_mean) * np.array(X_tr['cp_time_24']).reshape((N_tr, 1))\n",
    "    X_val_c_mean_24 = np.exp(X_val_c_mean) * np.array(X_val['cp_time_24']).reshape((N_val, 1))\n",
    "    X_test_c_mean_24 = np.exp(X_test_c_mean) * np.array(X_test['cp_time_24']).reshape((N_test, 1))\n",
    "    \n",
    "    #48\n",
    "    X_tr_g_mean_48 = np.exp(X_tr_g_mean) * np.array(X_tr['cp_time_48']).reshape((N_tr, 1))*2\n",
    "    X_val_g_mean_48 = np.exp(X_val_g_mean) * np.array(X_val['cp_time_48']).reshape((N_val, 1))*2\n",
    "    X_test_g_mean_48 = np.exp(X_test_g_mean) * np.array(X_test['cp_time_48']).reshape((N_test, 1))*2\n",
    "    \n",
    "    X_tr_c_mean_48 = np.exp(X_tr_c_mean) * np.array(X_tr['cp_time_48']).reshape((N_tr, 1))*2\n",
    "    X_val_c_mean_48 = np.exp(X_val_c_mean) * np.array(X_val['cp_time_48']).reshape((N_val, 1))*2\n",
    "    X_test_c_mean_48 = np.exp(X_test_c_mean) * np.array(X_test['cp_time_48']).reshape((N_test, 1))*2\n",
    "    \n",
    "    #72\n",
    "    X_tr_g_mean_72 = np.exp(X_tr_g_mean) * np.array(X_tr['cp_time_72']).reshape((N_tr, 1))*3\n",
    "    X_val_g_mean_72 = np.exp(X_val_g_mean) * np.array(X_val['cp_time_72']).reshape((N_val, 1))*3\n",
    "    X_test_g_mean_72 = np.exp(X_test_g_mean) * np.array(X_test['cp_time_72']).reshape((N_test, 1))*3\n",
    "    \n",
    "    X_tr_c_mean_72 = np.exp(X_tr_c_mean) * np.array(X_tr['cp_time_72']).reshape((N_tr, 1))*3\n",
    "    X_val_c_mean_72 = np.exp(X_val_c_mean) * np.array(X_val['cp_time_72']).reshape((N_val, 1))*3\n",
    "    X_test_c_mean_72 = np.exp(X_test_c_mean) * np.array(X_test['cp_time_72']).reshape((N_test, 1))*3\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Merge\n",
    "    new_X_tr = np.concatenate([X_tr_others, X_tr_pca_g, X_tr_pca_c, #X_tr[g_cols+c_cols], \n",
    "                              X_tr_g_var, X_tr_c_var, X_tr_g_mean, X_tr_c_mean, X_tr_mean_diff,\n",
    "                              X_tr_g_quantiles, X_tr_c_quantiles, X_tr_g_skew, X_tr_c_skew,\n",
    "                              X_tr_g_kurt, X_tr_c_kurt,\n",
    "                              X_tr_g_mean_24, X_tr_c_mean_24,\n",
    "                              X_tr_g_mean_48, X_tr_c_mean_48,\n",
    "                              X_tr_g_mean_72, X_tr_c_mean_72], axis=1)\n",
    "    \n",
    "    new_X_val = np.concatenate([X_val_others, X_val_pca_g, X_val_pca_c, #X_val[g_cols+c_cols],\n",
    "                               X_val_g_var, X_val_c_var, X_val_g_mean, X_val_c_mean, X_val_mean_diff,\n",
    "                               X_val_g_quantiles, X_val_c_quantiles, X_val_g_skew, X_val_c_skew,\n",
    "                               X_val_g_kurt, X_val_c_kurt,\n",
    "                               X_val_g_mean_24, X_val_c_mean_24,\n",
    "                               X_val_g_mean_48, X_val_c_mean_48,\n",
    "                               X_val_g_mean_72, X_val_c_mean_72], axis=1)\n",
    "    \n",
    "    new_X_test = np.concatenate([X_test_others, X_test_pca_g, X_test_pca_c, #X_test[g_cols+c_cols],\n",
    "                                X_test_g_var, X_test_c_var, X_test_g_mean, X_test_c_mean, X_test_mean_diff,\n",
    "                                X_test_g_quantiles, X_test_c_quantiles, X_test_g_skew, X_test_c_skew,\n",
    "                                X_test_g_kurt, X_test_c_kurt,\n",
    "                                X_test_g_mean_24, X_test_c_mean_24,\n",
    "                                X_test_g_mean_48, X_test_c_mean_48,\n",
    "                                X_test_g_mean_72, X_test_c_mean_72], axis=1)\n",
    "    \n",
    "    print(\"Number of features: {}\".format(new_X_tr.shape[1]))\n",
    "        \n",
    "    return new_X_tr, new_X_val, new_X_test\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:17.572473Z",
     "iopub.status.busy": "2020-11-28T12:01:17.571405Z",
     "iopub.status.idle": "2020-11-28T12:01:17.575403Z",
     "shell.execute_reply": "2020-11-28T12:01:17.574749Z"
    },
    "papermill": {
     "duration": 0.041482,
     "end_time": "2020-11-28T12:01:17.575539",
     "exception": false,
     "start_time": "2020-11-28T12:01:17.534057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5 or lr <= 0.00001:\n",
    "        return lr\n",
    "    elif epoch < 100:\n",
    "        return lr/1.05\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "def run_model_kfold(X_train, Y_train, X_test, test_id, num_folds=5, num_comp_g=200, num_comp_c=20):\n",
    "    #mskf = MultilabelStratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "    #for train_indices, val_indices in mskf.split(X_train, Y_train):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=2020)\n",
    "    val_loss_hist = []\n",
    "    \n",
    "    for train_indices, val_indices in kf.split(X_train, Y_train):\n",
    " \n",
    "        X_tr, X_val, X_test_pca = generate_X_pca(X_train.iloc[train_indices,:], \n",
    "                                             X_train.iloc[val_indices,:], \n",
    "                                             X_test, \n",
    "                                             num_comp_g=num_comp_g, \n",
    "                                             num_comp_c=num_comp_c)\n",
    "    \n",
    "        Y_tr, Y_val = Y_train.iloc[train_indices,:], Y_train.iloc[val_indices,:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = create_model(X_tr.shape[1], Y_train.shape[1])\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "        lr_decay = LearningRateScheduler(scheduler)\n",
    "        \n",
    "        hist = model.fit(X_tr, Y_tr, \n",
    "                  validation_data = (X_val, Y_val),\n",
    "                  batch_size=512, epochs=200, callbacks=[es, lr_decay])\n",
    "        \n",
    "        val_loss_hist.append(hist.history['val_loss'][-1])\n",
    "        \n",
    "        \n",
    "        submission.loc[test_id,:] += model.predict(X_test_pca)/num_folds\n",
    "    \n",
    "    print(\"Validation Losses: {}\".format(val_loss_hist))\n",
    "    print(\"Mean Validation Loss: {}\".format(np.mean(val_loss_hist)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:17.620754Z",
     "iopub.status.busy": "2020-11-28T12:01:17.619711Z",
     "iopub.status.idle": "2020-11-28T12:01:17.623216Z",
     "shell.execute_reply": "2020-11-28T12:01:17.622563Z"
    },
    "papermill": {
     "duration": 0.029866,
     "end_time": "2020-11-28T12:01:17.623338",
     "exception": false,
     "start_time": "2020-11-28T12:01:17.593472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "def create_model(input_shape, num_outputs):\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        keras.Input(shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(64, activation='relu'), \n",
    "        BatchNormalization(),\n",
    "        \n",
    "        \n",
    "        Dense(num_outputs, activation='sigmoid') \n",
    "    ])\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:01:17.666330Z",
     "iopub.status.busy": "2020-11-28T12:01:17.665319Z",
     "iopub.status.idle": "2020-11-28T12:06:31.414061Z",
     "shell.execute_reply": "2020-11-28T12:06:31.402675Z"
    },
    "papermill": {
     "duration": 313.77292,
     "end_time": "2020-11-28T12:06:31.414206",
     "exception": false,
     "start_time": "2020-11-28T12:01:17.641286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.4618 - val_loss: 0.0899\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0217\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0202\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0193\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0171\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0171\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0169\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 00029: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4635 - val_loss: 0.1447\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0361 - val_loss: 0.0268\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0191\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 00027: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4675 - val_loss: 0.1576\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0368 - val_loss: 0.0223\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0180\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0176\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0173\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 00034: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4623 - val_loss: 0.0882\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0223\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0189\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0185\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0176\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0176\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0175\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0175\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0175\n",
      "Epoch 00025: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.4547 - val_loss: 0.1006\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0239\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0193\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0190\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0184\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0182\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0177\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0174\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0173\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0173\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0172\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0173\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0172\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 00035: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4635 - val_loss: 0.0967\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0224\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0207\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0184\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0172\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0171\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0171\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 00032: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4603 - val_loss: 0.1077\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0223\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0200\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0181\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0168\n",
      "Epoch 00027: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4607 - val_loss: 0.1160\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0220\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0201\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 00024: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4585 - val_loss: 0.0974\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0354 - val_loss: 0.0232\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0193\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 00029: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4595 - val_loss: 0.1240\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0246\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 00024: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4603 - val_loss: 0.1006\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0238\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0188\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0183\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0180\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0177\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0175\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0175\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0173\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0171\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 00027: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4587 - val_loss: 0.0905\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0356 - val_loss: 0.0240\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0188\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0175\n",
      "Epoch 00025: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4591 - val_loss: 0.0753\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0359 - val_loss: 0.0227\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0197\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0193\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0190\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0189\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0185\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0183\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0182\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0182\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0179\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0178\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0178\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0178\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0178\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0178\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0177\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0178\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0177\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0178\n",
      "Epoch 00030: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.4591 - val_loss: 0.0874\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0361 - val_loss: 0.0216\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0195\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0186\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0176\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0169\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0165\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 00028: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4634 - val_loss: 0.1825\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0364 - val_loss: 0.0241\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0205\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0194\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 00034: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4631 - val_loss: 0.0796\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0367 - val_loss: 0.0213\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0197\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0187\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0180\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0174\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0170\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0165\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 00034: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4585 - val_loss: 0.0639\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0216\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0202\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0193\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0179\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0175\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0170\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0169\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0169\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0168\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0168\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 00032: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4611 - val_loss: 0.0950\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0357 - val_loss: 0.0239\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0197\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0194\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0189\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0183\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 00021: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4639 - val_loss: 0.0910\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0367 - val_loss: 0.0216\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0200\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0182\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0171\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0171\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0170\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0170\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 00021: early stopping\n",
      "Number of features: 134\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4579 - val_loss: 0.1177\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0357 - val_loss: 0.0231\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0208\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0179\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0176\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0175\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0172\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 00028: early stopping\n",
      "Validation Losses: [0.016957968473434448, 0.016583004966378212, 0.016903212293982506, 0.017532138153910637, 0.017249345779418945, 0.017095737159252167, 0.01675732433795929, 0.016834689304232597, 0.016479885205626488, 0.016671793535351753, 0.017033103853464127, 0.017477422952651978, 0.01780926063656807, 0.016216186806559563, 0.016591055318713188, 0.016110064461827278, 0.016745813190937042, 0.017727673053741455, 0.017082108184695244, 0.0170441921800375]\n",
      "Mean Validation Loss: 0.016945098992437124\n"
     ]
    }
   ],
   "source": [
    "num_comp_g = 60\n",
    "num_comp_c = 10\n",
    "run_model_kfold(X_train, Y_train, X_test, id_test, num_folds=20, num_comp_g=num_comp_g, num_comp_c=num_comp_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T12:06:34.762296Z",
     "iopub.status.busy": "2020-11-28T12:06:34.761431Z",
     "iopub.status.idle": "2020-11-28T12:06:37.211099Z",
     "shell.execute_reply": "2020-11-28T12:06:37.210434Z"
    },
    "papermill": {
     "duration": 4.139938,
     "end_time": "2020-11-28T12:06:37.211242",
     "exception": false,
     "start_time": "2020-11-28T12:06:33.071304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.reset_index().to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.692274,
     "end_time": "2020-11-28T12:06:40.550602",
     "exception": false,
     "start_time": "2020-11-28T12:06:38.858328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 346.789844,
   "end_time": "2020-11-28T12:06:42.352061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-28T12:00:55.562217",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
